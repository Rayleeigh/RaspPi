# Open WebUI + Ollama Setup

1. Run `docker-compose up -d`.
2. Go to `http://<RaspberryPiIP>:8082`.
3. Try chatting with a local AI model (default is LLaMA2).
4. You can pull models using `ollama pull mistral` etc.
